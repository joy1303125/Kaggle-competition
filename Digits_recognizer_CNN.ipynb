{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO36yeDtBZnNITIA26puUuX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joy1303125/Kaggle-competition/blob/main/Digits_recognizer_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vSoNfNSTMF1",
        "outputId": "59177ae3-1877-42c5-b1c8-e35da8be58b3"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzzhUGjFVD9d"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqZnO81STrrT"
      },
      "source": [
        "train = pd.read_csv('/content/train.csv')\r\n",
        "test= pd.read_csv('/content/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "AhiJRWA2Tr2P",
        "outputId": "df2d6bf0-d4c6-4f4a-953c-a63858c00233"
      },
      "source": [
        "import seaborn as sns\r\n",
        "sns.countplot(train['label'])\r\n",
        "train['label'].value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4684\n",
              "7    4401\n",
              "3    4351\n",
              "9    4188\n",
              "2    4177\n",
              "6    4137\n",
              "0    4132\n",
              "4    4072\n",
              "8    4063\n",
              "5    3795\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "yZvCpbGETr45",
        "outputId": "8fe15867-b2c7-4841-fc48-d3e4ac257c7b"
      },
      "source": [
        "orig_labels = train['label']\r\n",
        "y = tf.keras.utils.to_categorical(orig_labels) # one-hot encoding\r\n",
        "train.drop('label', axis=1, inplace=True)\r\n",
        "train.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 784 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   pixel0  pixel1  pixel2  pixel3  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0       0       0       0       0  ...         0         0         0         0\n",
              "1       0       0       0       0  ...         0         0         0         0\n",
              "2       0       0       0       0  ...         0         0         0         0\n",
              "3       0       0       0       0  ...         0         0         0         0\n",
              "4       0       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 784 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pRXJxiKUhAd"
      },
      "source": [
        "train_arr = np.array(train).reshape(-1, 28, 28, 1)\r\n",
        "test_arr = np.array(test).reshape(-1, 28, 28, 1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0E-4M4uUhJ0"
      },
      "source": [
        "train = train_arr/255.0\r\n",
        "test = test_arr/255.0"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsCASfI0fGYy"
      },
      "source": [
        "X_train, X_val, Y_train, Y_val = train_test_split(train, y, test_size = 0.1, random_state=2)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDqfZVCgb4xl"
      },
      "source": [
        "checkpoint_path = \"logs/checkpoints/\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUXs2dXhzxqx",
        "outputId": "413e07f9-5b50-4e19-dedd-1c9a79ecfd4d"
      },
      "source": [
        "model = tf.keras.models.Sequential([\r\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), input_shape=(28, 28, 1), activation='relu', padding=\"SAME\"),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu, padding=\"SAME\"),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.Dropout(0.5),\r\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation=tf.nn.relu, padding=\"SAME\"),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.BatchNormalization(),\r\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation=tf.nn.relu, padding=\"SAME\"),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.BatchNormalization(),\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\r\n",
        "    tf.keras.layers.Dropout(0.5),\r\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\r\n",
        "])\r\n",
        "\r\n",
        "epochs=50\r\n",
        "\r\n",
        "callbacks = [\r\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\r\n",
        "                                        monitor=\"accuracy\",\r\n",
        "                                        save_best_only=True,\r\n",
        "                                        save_weights_only=True),\r\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=15)\r\n",
        "]\r\n",
        "\r\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\r\n",
        "history = model.fit(train, y, epochs=epochs, callbacks=callbacks, batch_size=64)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.3496 - accuracy: 0.8909\n",
            "Epoch 2/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0975 - accuracy: 0.9720\n",
            "Epoch 3/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0718 - accuracy: 0.9792\n",
            "Epoch 4/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0655 - accuracy: 0.9804\n",
            "Epoch 5/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0532 - accuracy: 0.9845\n",
            "Epoch 6/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0498 - accuracy: 0.9849\n",
            "Epoch 7/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0486 - accuracy: 0.9859\n",
            "Epoch 8/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0420 - accuracy: 0.9875\n",
            "Epoch 9/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0396 - accuracy: 0.9882\n",
            "Epoch 10/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0366 - accuracy: 0.9886\n",
            "Epoch 11/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0366 - accuracy: 0.9885\n",
            "Epoch 12/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0323 - accuracy: 0.9902\n",
            "Epoch 13/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0320 - accuracy: 0.9904\n",
            "Epoch 14/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0295 - accuracy: 0.9908\n",
            "Epoch 15/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0281 - accuracy: 0.9914\n",
            "Epoch 16/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0286 - accuracy: 0.9916\n",
            "Epoch 17/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0238 - accuracy: 0.9923\n",
            "Epoch 18/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0232 - accuracy: 0.9930\n",
            "Epoch 19/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0254 - accuracy: 0.9922\n",
            "Epoch 20/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0220 - accuracy: 0.9933\n",
            "Epoch 21/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0213 - accuracy: 0.9932\n",
            "Epoch 22/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0217 - accuracy: 0.9932\n",
            "Epoch 23/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0193 - accuracy: 0.9941\n",
            "Epoch 24/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0213 - accuracy: 0.9933\n",
            "Epoch 25/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0175 - accuracy: 0.9946\n",
            "Epoch 26/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0169 - accuracy: 0.9948\n",
            "Epoch 27/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0161 - accuracy: 0.9948\n",
            "Epoch 28/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0162 - accuracy: 0.9947\n",
            "Epoch 29/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0179 - accuracy: 0.9942\n",
            "Epoch 30/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0155 - accuracy: 0.9950\n",
            "Epoch 31/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0148 - accuracy: 0.9953\n",
            "Epoch 32/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0149 - accuracy: 0.9953\n",
            "Epoch 33/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0136 - accuracy: 0.9959\n",
            "Epoch 34/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0152 - accuracy: 0.9956\n",
            "Epoch 35/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0129 - accuracy: 0.9962\n",
            "Epoch 36/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0136 - accuracy: 0.9957\n",
            "Epoch 37/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0143 - accuracy: 0.9953\n",
            "Epoch 38/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0149 - accuracy: 0.9954\n",
            "Epoch 39/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0128 - accuracy: 0.9961\n",
            "Epoch 40/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0130 - accuracy: 0.9960\n",
            "Epoch 41/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0117 - accuracy: 0.9964\n",
            "Epoch 42/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0130 - accuracy: 0.9961\n",
            "Epoch 43/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0117 - accuracy: 0.9963\n",
            "Epoch 44/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0125 - accuracy: 0.9961\n",
            "Epoch 45/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0119 - accuracy: 0.9964\n",
            "Epoch 46/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0117 - accuracy: 0.9963\n",
            "Epoch 47/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0110 - accuracy: 0.9962\n",
            "Epoch 48/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0125 - accuracy: 0.9961\n",
            "Epoch 49/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0117 - accuracy: 0.9961\n",
            "Epoch 50/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0083 - accuracy: 0.9972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S15eCDbQzxwp"
      },
      "source": [
        "datagen = ImageDataGenerator(\r\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\r\n",
        "        zoom_range = 0.1, # Randomly zoom image \r\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\r\n",
        "        height_shift_range=0.1)  # randomly shift images vertically (fraction of total height)\r\n",
        "\r\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9AbDeTidQYI"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.image as mpimg\r\n",
        "import seaborn as sns\r\n",
        "%matplotlib inline\r\n",
        "sns.set(style='white', context='notebook', palette='deep')\r\n",
        "\r\n",
        "# modeling\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "# keras\r\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.callbacks import LearningRateScheduler\r\n",
        "from keras import models\r\n",
        "\r\n",
        "np.random.seed(2)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JXGH52Lzxz1",
        "outputId": "6dadb525-3c90-4290-eaf3-f6633b71aea2"
      },
      "source": [
        "model = tf.keras.models.Sequential([\r\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), input_shape=(28, 28, 1), activation='relu', padding=\"SAME\"),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu, padding=\"SAME\"),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.Dropout(0.5),\r\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation=tf.nn.relu, padding=\"SAME\"),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.BatchNormalization(),\r\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation=tf.nn.relu, padding=\"SAME\"),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.BatchNormalization(),\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\r\n",
        "    tf.keras.layers.Dropout(0.5),\r\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\r\n",
        "])\r\n",
        "\r\n",
        "epochs=50\r\n",
        "\r\n",
        "callbacks = [\r\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\r\n",
        "                                        monitor=\"accuracy\",\r\n",
        "                                        save_best_only=True,\r\n",
        "                                        save_weights_only=True),\r\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=15)\r\n",
        "]\r\n",
        "\r\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\r\n",
        "history = model.fit(train, y, epochs=epochs, callbacks=callbacks, batch_size=64)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.3503 - accuracy: 0.8888\n",
            "Epoch 2/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0967 - accuracy: 0.9711\n",
            "Epoch 3/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0765 - accuracy: 0.9770\n",
            "Epoch 4/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0628 - accuracy: 0.9817\n",
            "Epoch 5/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0553 - accuracy: 0.9830\n",
            "Epoch 6/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0516 - accuracy: 0.9841\n",
            "Epoch 7/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0454 - accuracy: 0.9865\n",
            "Epoch 8/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0454 - accuracy: 0.9863\n",
            "Epoch 9/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0397 - accuracy: 0.9877\n",
            "Epoch 10/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0369 - accuracy: 0.9888\n",
            "Epoch 11/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0344 - accuracy: 0.9898\n",
            "Epoch 12/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0337 - accuracy: 0.9898\n",
            "Epoch 13/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0313 - accuracy: 0.9900\n",
            "Epoch 14/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0319 - accuracy: 0.9905\n",
            "Epoch 15/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0255 - accuracy: 0.9922\n",
            "Epoch 16/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0285 - accuracy: 0.9915\n",
            "Epoch 17/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0245 - accuracy: 0.9924\n",
            "Epoch 18/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0239 - accuracy: 0.9930\n",
            "Epoch 19/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0268 - accuracy: 0.9918\n",
            "Epoch 20/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0242 - accuracy: 0.9927\n",
            "Epoch 21/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0188 - accuracy: 0.9945\n",
            "Epoch 22/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0222 - accuracy: 0.9934\n",
            "Epoch 23/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0203 - accuracy: 0.9936\n",
            "Epoch 24/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0196 - accuracy: 0.9941\n",
            "Epoch 25/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0196 - accuracy: 0.9936\n",
            "Epoch 26/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0185 - accuracy: 0.9944\n",
            "Epoch 27/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0197 - accuracy: 0.9936\n",
            "Epoch 28/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0168 - accuracy: 0.9946\n",
            "Epoch 29/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0172 - accuracy: 0.9947\n",
            "Epoch 30/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0167 - accuracy: 0.9949\n",
            "Epoch 31/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0151 - accuracy: 0.9957\n",
            "Epoch 32/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0143 - accuracy: 0.9955\n",
            "Epoch 33/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0149 - accuracy: 0.9956\n",
            "Epoch 34/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0163 - accuracy: 0.9953\n",
            "Epoch 35/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0173 - accuracy: 0.9951\n",
            "Epoch 36/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0142 - accuracy: 0.9958\n",
            "Epoch 37/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0145 - accuracy: 0.9955\n",
            "Epoch 38/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0143 - accuracy: 0.9953\n",
            "Epoch 39/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0143 - accuracy: 0.9955\n",
            "Epoch 40/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0128 - accuracy: 0.9959\n",
            "Epoch 41/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0129 - accuracy: 0.9963\n",
            "Epoch 42/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0137 - accuracy: 0.9959\n",
            "Epoch 43/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0135 - accuracy: 0.9962\n",
            "Epoch 44/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0120 - accuracy: 0.9966\n",
            "Epoch 45/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0137 - accuracy: 0.9961\n",
            "Epoch 46/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0125 - accuracy: 0.9961\n",
            "Epoch 47/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0116 - accuracy: 0.9961\n",
            "Epoch 48/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0120 - accuracy: 0.9965\n",
            "Epoch 49/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0107 - accuracy: 0.9965\n",
            "Epoch 50/50\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0100 - accuracy: 0.9967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0os47vkgc45"
      },
      "source": [
        "model1 = tf.keras.models.Sequential([\r\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), input_shape=(28, 28, 1), activation='relu', padding=\"SAME\"),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu, padding=\"SAME\"),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.Dropout(0.5),\r\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation=tf.nn.relu, padding=\"SAME\"),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.BatchNormalization(),\r\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation=tf.nn.relu, padding=\"SAME\"),\r\n",
        "    tf.keras.layers.MaxPooling2D(),\r\n",
        "    tf.keras.layers.BatchNormalization(),\r\n",
        "    tf.keras.layers.Flatten(),\r\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\r\n",
        "    tf.keras.layers.Dropout(0.5),\r\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\r\n",
        "])\r\n",
        "\r\n",
        "epochs=50\r\n",
        "\r\n",
        "callbacks = [\r\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\r\n",
        "                                        monitor=\"accuracy\",\r\n",
        "                                        save_best_only=True,\r\n",
        "                                        save_weights_only=True),\r\n",
        "    tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", patience=15)\r\n",
        "]\r\n",
        "\r\n",
        "model1.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeWD0BtcfgB2",
        "outputId": "46100865-87a5-4cf8-a159-cdb4c047e01f"
      },
      "source": [
        "history = model1.fit_generator(datagen.flow(X_train,Y_train, batch_size=64),\r\n",
        "                              epochs = epochs, validation_data = (X_val,Y_val),\r\n",
        "                              verbose = 2, steps_per_epoch=X_train.shape[0] // 64\r\n",
        "                              ,  callbacks=callbacks)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "590/590 - 10s - loss: 0.5000 - accuracy: 0.8401 - val_loss: 0.0742 - val_accuracy: 0.9802\n",
            "Epoch 2/50\n",
            "590/590 - 10s - loss: 0.1488 - accuracy: 0.9567 - val_loss: 0.0867 - val_accuracy: 0.9776\n",
            "Epoch 3/50\n",
            "590/590 - 9s - loss: 0.1180 - accuracy: 0.9653 - val_loss: 0.0512 - val_accuracy: 0.9845\n",
            "Epoch 4/50\n",
            "590/590 - 9s - loss: 0.1015 - accuracy: 0.9705 - val_loss: 0.0480 - val_accuracy: 0.9874\n",
            "Epoch 5/50\n",
            "590/590 - 10s - loss: 0.0877 - accuracy: 0.9745 - val_loss: 0.0366 - val_accuracy: 0.9883\n",
            "Epoch 6/50\n",
            "590/590 - 9s - loss: 0.0799 - accuracy: 0.9761 - val_loss: 0.0356 - val_accuracy: 0.9876\n",
            "Epoch 7/50\n",
            "590/590 - 9s - loss: 0.0756 - accuracy: 0.9785 - val_loss: 0.0339 - val_accuracy: 0.9917\n",
            "Epoch 8/50\n",
            "590/590 - 9s - loss: 0.0700 - accuracy: 0.9791 - val_loss: 0.0357 - val_accuracy: 0.9893\n",
            "Epoch 9/50\n",
            "590/590 - 9s - loss: 0.0708 - accuracy: 0.9793 - val_loss: 0.0761 - val_accuracy: 0.9800\n",
            "Epoch 10/50\n",
            "590/590 - 9s - loss: 0.0629 - accuracy: 0.9812 - val_loss: 0.0364 - val_accuracy: 0.9900\n",
            "Epoch 11/50\n",
            "590/590 - 9s - loss: 0.0614 - accuracy: 0.9818 - val_loss: 0.0272 - val_accuracy: 0.9929\n",
            "Epoch 12/50\n",
            "590/590 - 9s - loss: 0.0632 - accuracy: 0.9815 - val_loss: 0.0244 - val_accuracy: 0.9931\n",
            "Epoch 13/50\n",
            "590/590 - 9s - loss: 0.0578 - accuracy: 0.9833 - val_loss: 0.0456 - val_accuracy: 0.9890\n",
            "Epoch 14/50\n",
            "590/590 - 10s - loss: 0.0519 - accuracy: 0.9848 - val_loss: 0.0279 - val_accuracy: 0.9919\n",
            "Epoch 15/50\n",
            "590/590 - 9s - loss: 0.0507 - accuracy: 0.9852 - val_loss: 0.0281 - val_accuracy: 0.9926\n",
            "Epoch 16/50\n",
            "590/590 - 9s - loss: 0.0565 - accuracy: 0.9843 - val_loss: 0.0221 - val_accuracy: 0.9936\n",
            "Epoch 17/50\n",
            "590/590 - 9s - loss: 0.0515 - accuracy: 0.9845 - val_loss: 0.0244 - val_accuracy: 0.9929\n",
            "Epoch 18/50\n",
            "590/590 - 9s - loss: 0.0515 - accuracy: 0.9846 - val_loss: 0.0254 - val_accuracy: 0.9924\n",
            "Epoch 19/50\n",
            "590/590 - 10s - loss: 0.0477 - accuracy: 0.9854 - val_loss: 0.0292 - val_accuracy: 0.9929\n",
            "Epoch 20/50\n",
            "590/590 - 10s - loss: 0.0473 - accuracy: 0.9863 - val_loss: 0.0339 - val_accuracy: 0.9914\n",
            "Epoch 21/50\n",
            "590/590 - 9s - loss: 0.0456 - accuracy: 0.9870 - val_loss: 0.0251 - val_accuracy: 0.9936\n",
            "Epoch 22/50\n",
            "590/590 - 9s - loss: 0.0474 - accuracy: 0.9864 - val_loss: 0.0262 - val_accuracy: 0.9929\n",
            "Epoch 23/50\n",
            "590/590 - 9s - loss: 0.0417 - accuracy: 0.9875 - val_loss: 0.0293 - val_accuracy: 0.9931\n",
            "Epoch 24/50\n",
            "590/590 - 10s - loss: 0.0443 - accuracy: 0.9873 - val_loss: 0.0210 - val_accuracy: 0.9952\n",
            "Epoch 25/50\n",
            "590/590 - 10s - loss: 0.0428 - accuracy: 0.9873 - val_loss: 0.0334 - val_accuracy: 0.9926\n",
            "Epoch 26/50\n",
            "590/590 - 9s - loss: 0.0408 - accuracy: 0.9880 - val_loss: 0.0368 - val_accuracy: 0.9919\n",
            "Epoch 27/50\n",
            "590/590 - 10s - loss: 0.0417 - accuracy: 0.9876 - val_loss: 0.0240 - val_accuracy: 0.9940\n",
            "Epoch 28/50\n",
            "590/590 - 9s - loss: 0.0397 - accuracy: 0.9884 - val_loss: 0.0242 - val_accuracy: 0.9933\n",
            "Epoch 29/50\n",
            "590/590 - 9s - loss: 0.0400 - accuracy: 0.9884 - val_loss: 0.0226 - val_accuracy: 0.9945\n",
            "Epoch 30/50\n",
            "590/590 - 9s - loss: 0.0389 - accuracy: 0.9884 - val_loss: 0.0197 - val_accuracy: 0.9945\n",
            "Epoch 31/50\n",
            "590/590 - 9s - loss: 0.0400 - accuracy: 0.9884 - val_loss: 0.0235 - val_accuracy: 0.9938\n",
            "Epoch 32/50\n",
            "590/590 - 9s - loss: 0.0356 - accuracy: 0.9885 - val_loss: 0.0239 - val_accuracy: 0.9938\n",
            "Epoch 33/50\n",
            "590/590 - 9s - loss: 0.0359 - accuracy: 0.9888 - val_loss: 0.0279 - val_accuracy: 0.9938\n",
            "Epoch 34/50\n",
            "590/590 - 9s - loss: 0.0371 - accuracy: 0.9885 - val_loss: 0.0271 - val_accuracy: 0.9933\n",
            "Epoch 35/50\n",
            "590/590 - 9s - loss: 0.0365 - accuracy: 0.9893 - val_loss: 0.0195 - val_accuracy: 0.9940\n",
            "Epoch 36/50\n",
            "590/590 - 10s - loss: 0.0350 - accuracy: 0.9898 - val_loss: 0.0232 - val_accuracy: 0.9931\n",
            "Epoch 37/50\n",
            "590/590 - 9s - loss: 0.0345 - accuracy: 0.9898 - val_loss: 0.0220 - val_accuracy: 0.9945\n",
            "Epoch 38/50\n",
            "590/590 - 9s - loss: 0.0334 - accuracy: 0.9904 - val_loss: 0.0240 - val_accuracy: 0.9933\n",
            "Epoch 39/50\n",
            "590/590 - 9s - loss: 0.0326 - accuracy: 0.9903 - val_loss: 0.0203 - val_accuracy: 0.9940\n",
            "Epoch 40/50\n",
            "590/590 - 9s - loss: 0.0347 - accuracy: 0.9891 - val_loss: 0.0254 - val_accuracy: 0.9938\n",
            "Epoch 41/50\n",
            "590/590 - 9s - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.0204 - val_accuracy: 0.9940\n",
            "Epoch 42/50\n",
            "590/590 - 9s - loss: 0.0338 - accuracy: 0.9902 - val_loss: 0.0544 - val_accuracy: 0.9860\n",
            "Epoch 43/50\n",
            "590/590 - 9s - loss: 0.0332 - accuracy: 0.9901 - val_loss: 0.0231 - val_accuracy: 0.9931\n",
            "Epoch 44/50\n",
            "590/590 - 9s - loss: 0.0317 - accuracy: 0.9907 - val_loss: 0.0230 - val_accuracy: 0.9955\n",
            "Epoch 45/50\n",
            "590/590 - 9s - loss: 0.0332 - accuracy: 0.9902 - val_loss: 0.0194 - val_accuracy: 0.9950\n",
            "Epoch 46/50\n",
            "590/590 - 10s - loss: 0.0336 - accuracy: 0.9899 - val_loss: 0.0178 - val_accuracy: 0.9952\n",
            "Epoch 47/50\n",
            "590/590 - 10s - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.0181 - val_accuracy: 0.9955\n",
            "Epoch 48/50\n",
            "590/590 - 9s - loss: 0.0300 - accuracy: 0.9909 - val_loss: 0.0222 - val_accuracy: 0.9938\n",
            "Epoch 49/50\n",
            "590/590 - 9s - loss: 0.0305 - accuracy: 0.9910 - val_loss: 0.0200 - val_accuracy: 0.9936\n",
            "Epoch 50/50\n",
            "590/590 - 9s - loss: 0.0291 - accuracy: 0.9917 - val_loss: 0.0269 - val_accuracy: 0.9924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KesgY_xDlKWs"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.base import BaseEstimator\r\n",
        "class Never5Classifier(BaseEstimator):\r\n",
        "    def fit(self, X, y=None):\r\n",
        "        pass\r\n",
        "    def predict(self, X):\r\n",
        "        return np.zeros((len(X), 1), dtype=bool)\r\n",
        " \r\n",
        "never_5_clf = Never5Classifier()\r\n",
        "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZu02kV0me4z",
        "outputId": "53d28718-3453-4920-f522-2362ab2d1201"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "Y_pred = model1.predict(X_val)\r\n",
        "# Convert predictions classes to one hot vectors \r\n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1) \r\n",
        "# Convert validation observations to one hot vectors\r\n",
        "Y_true = np.argmax(Y_val,axis = 1) \r\n",
        "# compute the confusion matrix\r\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \r\n",
        "# plot the confusion matrix\r\n",
        "#plot_confusion_matrix(confusion_mtx, classes = range(10)) \r\n",
        "confusion_mtx"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[411,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  0, 479,   0,   0,   0,   0,   0,   3,   3,   0],\n",
              "       [  0,   0, 402,   1,   0,   0,   0,   0,   0,   0],\n",
              "       [  0,   0,   0, 417,   0,   0,   0,   0,   1,   0],\n",
              "       [  0,   0,   0,   0, 452,   0,   2,   0,   0,   7],\n",
              "       [  0,   0,   0,   2,   0, 367,   2,   0,   1,   0],\n",
              "       [  0,   0,   0,   0,   0,   1, 410,   0,   2,   0],\n",
              "       [  0,   0,   2,   1,   0,   0,   0, 443,   0,   0],\n",
              "       [  0,   0,   0,   0,   1,   0,   0,   0, 381,   0],\n",
              "       [  1,   0,   0,   0,   1,   0,   0,   1,   0, 406]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh5cOvVSozde",
        "outputId": "c162b86b-5533-4973-f6c1-25c93d10417f"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvKPFs2Lojfl"
      },
      "source": [
        "results = model1.predict(test)\r\n",
        "\r\n",
        "# select the indix with the maximum probability\r\n",
        "results = np.argmax(results,axis = 1)\r\n",
        "\r\n",
        "results = pd.Series(results,name=\"Label\")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcpPTXoAo2uS"
      },
      "source": [
        "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\r\n",
        "\r\n",
        "submission.to_csv(\"digits_cnn_data_gen.csv\",index=False)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2SpR1syr52i"
      },
      "source": [
        "results = model.predict(test)\r\n",
        "\r\n",
        "# select the indix with the maximum probability\r\n",
        "results = np.argmax(results,axis = 1)\r\n",
        "\r\n",
        "results = pd.Series(results,name=\"Label\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFVyCh2zsEqo"
      },
      "source": [
        "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\r\n",
        "\r\n",
        "submission.to_csv(\"digits_cnn.csv\",index=False)"
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}